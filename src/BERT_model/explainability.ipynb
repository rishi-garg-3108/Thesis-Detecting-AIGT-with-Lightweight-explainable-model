{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb898e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers_interpret import SequenceClassificationExplainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2dbab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------\n",
    "# 0. Model & Tokenizer loading\n",
    "# -------------------------------------------------------\n",
    "model_name = \"/path/to/model\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45cee86",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. Load Dataset Using Your Preferred Method\n",
    "# -------------------------------------------------------\n",
    "dataset_path = \"/path/to/dataset\"\n",
    "tweets_df = pd.read_json(dataset_path, lines=True)  # Using your standard method\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Extract Relevant Columns\n",
    "# -------------------------------------------------------\n",
    "# Assuming 'tweets' column contains the text and 'artificial' column contains the labels (0=Human, 1=AI)\n",
    "tweets = tweets_df[\"tweets\"].tolist()\n",
    "labels = tweets_df[\"artificial\"].tolist()  # 0 for human-written, 1 for AI-generated\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Select 'n' Random Tweets\n",
    "# -------------------------------------------------------\n",
    "n = 77  # Change this number as needed\n",
    "selected_indices = random.sample(range(len(tweets)), n)\n",
    "selected_tweets = [tweets[i] for i in selected_indices]\n",
    "selected_labels = [labels[i] for i in selected_indices]\n",
    "\n",
    "\n",
    "\n",
    "# Initialize interpretability tool\n",
    "cls_explainer = SequenceClassificationExplainer(model, tokenizer)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. Run Interpretability Analysis on Selected Tweets\n",
    "# -------------------------------------------------------\n",
    "for i, (tweet, label) in enumerate(zip(selected_tweets, selected_labels)):\n",
    "    print(f\"\\n{'-'*60}\\nTweet {i+1}:\")\n",
    "    print(f\"Original Text: {tweet}\")\n",
    "    print(f\"Actual Label: {'AI-Generated' if label == 1 else 'Human-Written'}\")\n",
    "\n",
    "    # Get word attributions\n",
    "    word_attributions = cls_explainer(tweet)\n",
    "\n",
    "    # Print word attributions\n",
    "    print(\"\\nWord Attributions:\")\n",
    "    for word, score in word_attributions:\n",
    "        print(f\"{word:<12}: {score:.6f}\")\n",
    "\n",
    "    # Uncomment this line if using Jupyter Notebook to visualize explanations\n",
    "    # cls_explainer.visualize()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
